{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/gautamrmenon/vgg16-with-pytorch?scriptVersionId=143827129\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:33:27.360456Z","iopub.execute_input":"2023-09-22T04:33:27.361039Z","iopub.status.idle":"2023-09-22T04:33:28.363842Z","shell.execute_reply.started":"2023-09-22T04:33:27.361009Z","shell.execute_reply":"2023-09-22T04:33:28.362575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install torchmetrics mlxtend torchinfo","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:33:28.366452Z","iopub.execute_input":"2023-09-22T04:33:28.367178Z","iopub.status.idle":"2023-09-22T04:33:42.095919Z","shell.execute_reply.started":"2023-09-22T04:33:28.367137Z","shell.execute_reply":"2023-09-22T04:33:42.094684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nfrom torch.utils.data import DataLoader\nfrom torchinfo import summary\n\nfrom torchmetrics import ConfusionMatrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nimport random\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm.auto import trange,tqdm\nimport matplotlib.pyplot as plt\nfrom timeit import default_timer as timer","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:33:42.097585Z","iopub.execute_input":"2023-09-22T04:33:42.098265Z","iopub.status.idle":"2023-09-22T04:33:54.932682Z","shell.execute_reply.started":"2023-09-22T04:33:42.098227Z","shell.execute_reply":"2023-09-22T04:33:54.931708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FashionMNIST Dataset\n> Dataset : https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html","metadata":{}},{"cell_type":"markdown","source":"### Download Dataset   \n- Download train and test sets.\n- Apply transformations to image data.","metadata":{}},{"cell_type":"code","source":"train_data = datasets.FashionMNIST(root='data',\n                                  train=True,\n                                  transform=ToTensor(),\n                                  download=True)\ntest_data = datasets.FashionMNIST(root='data', \n                                train=False,\n                                transform=ToTensor(),\n                                download=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:33:54.93509Z","iopub.execute_input":"2023-09-22T04:33:54.93537Z","iopub.status.idle":"2023-09-22T04:34:04.275117Z","shell.execute_reply.started":"2023-09-22T04:33:54.935347Z","shell.execute_reply":"2023-09-22T04:34:04.274159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_data), len(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:04.276509Z","iopub.execute_input":"2023-09-22T04:34:04.277078Z","iopub.status.idle":"2023-09-22T04:34:04.287647Z","shell.execute_reply.started":"2023-09-22T04:34:04.277043Z","shell.execute_reply":"2023-09-22T04:34:04.286731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset Classes\n- FashionMNIST dataset has 10 classes of apparel.","metadata":{}},{"cell_type":"code","source":"class_names = train_data.classes\nclass_names","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:04.288652Z","iopub.execute_input":"2023-09-22T04:34:04.289273Z","iopub.status.idle":"2023-09-22T04:34:04.30941Z","shell.execute_reply.started":"2023-09-22T04:34:04.289239Z","shell.execute_reply":"2023-09-22T04:34:04.308449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset Classes with Indices","metadata":{}},{"cell_type":"code","source":"class_to_idx = train_data.class_to_idx\nclass_to_idx","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:04.310922Z","iopub.execute_input":"2023-09-22T04:34:04.311223Z","iopub.status.idle":"2023-09-22T04:34:04.321427Z","shell.execute_reply.started":"2023-09-22T04:34:04.311194Z","shell.execute_reply":"2023-09-22T04:34:04.320426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sample Image Shape and Label","metadata":{}},{"cell_type":"code","source":"img, label = train_data[0]\nimg.shape, label","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:04.322936Z","iopub.execute_input":"2023-09-22T04:34:04.323268Z","iopub.status.idle":"2023-09-22T04:34:04.350265Z","shell.execute_reply.started":"2023-09-22T04:34:04.323239Z","shell.execute_reply":"2023-09-22T04:34:04.349407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"plt.imshow(img.permute(1,2,0))\nplt.title(class_names[label])\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:04.351659Z","iopub.execute_input":"2023-09-22T04:34:04.351996Z","iopub.status.idle":"2023-09-22T04:34:04.557693Z","shell.execute_reply.started":"2023-09-22T04:34:04.351967Z","shell.execute_reply":"2023-09-22T04:34:04.556828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12, 12))\nrows, cols = 4, 4\nfor i in range(1, rows * cols + 1):\n    img, label = train_data[i]\n    fig.add_subplot(rows, cols, i)\n    plt.imshow(img.permute(1,2,0))\n    plt.title(class_names[label])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:04.562242Z","iopub.execute_input":"2023-09-22T04:34:04.56255Z","iopub.status.idle":"2023-09-22T04:34:05.940425Z","shell.execute_reply.started":"2023-09-22T04:34:04.562526Z","shell.execute_reply":"2023-09-22T04:34:05.939522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\n\ntrain_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n\ntest_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n\nlen(train_loader), len(test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:05.941569Z","iopub.execute_input":"2023-09-22T04:34:05.941846Z","iopub.status.idle":"2023-09-22T04:34:05.954248Z","shell.execute_reply.started":"2023-09-22T04:34:05.941823Z","shell.execute_reply":"2023-09-22T04:34:05.953343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features_batch, train_labels_batch = next(iter(train_loader))\ntrain_features_batch.shape, train_labels_batch.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:05.955772Z","iopub.execute_input":"2023-09-22T04:34:05.956381Z","iopub.status.idle":"2023-09-22T04:34:06.011967Z","shell.execute_reply.started":"2023-09-22T04:34:05.956348Z","shell.execute_reply":"2023-09-22T04:34:06.010928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\nimg, label = train_features_batch[rand_idx], train_labels_batch[rand_idx]\nplt.imshow(img.permute(1,2,0))\nplt.title(class_names[label])\nplt.axis(\"off\")\nprint(f\"Image shape: {img.shape}\")\nprint(f\"Label: {class_names[label]}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:06.013659Z","iopub.execute_input":"2023-09-22T04:34:06.014024Z","iopub.status.idle":"2023-09-22T04:34:06.194692Z","shell.execute_reply.started":"2023-09-22T04:34:06.013991Z","shell.execute_reply":"2023-09-22T04:34:06.193747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG16 Model Architecture\n> Architecture as per https://blog.paperspace.com/vgg-from-scratch-pytorch/","metadata":{}},{"cell_type":"code","source":"class VGG16(nn.Module):\n    \"\"\"\n        Implementation of VGG16 architecture.\n        \n        Args:\n            num_classes (int): Specify number of classes for multi-class classification task.\n            \n        Returns:\n            Training loss, Training accuracy, Testing loss, Testing accuracy, Total training time.\n    \"\"\"\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU())\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(), \n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU())\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU())\n        self.layer6 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU())\n        self.layer7 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer8 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer9 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer10 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer11 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer12 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer13 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(7*7*512, 4096),\n            nn.ReLU())\n        self.fc1 = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU())\n        self.fc2= nn.Sequential(\n            nn.Linear(4096, num_classes))\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = self.layer6(out)\n        out = self.layer7(out)\n        out = self.layer8(out)\n        out = self.layer9(out)\n        out = self.layer10(out)\n        out = self.layer11(out)\n        out = self.layer12(out)\n        out = self.layer13(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:06.197032Z","iopub.execute_input":"2023-09-22T04:34:06.197388Z","iopub.status.idle":"2023-09-22T04:34:06.221638Z","shell.execute_reply.started":"2023-09-22T04:34:06.197356Z","shell.execute_reply":"2023-09-22T04:34:06.21777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16 = VGG16(num_classes=100)\nsummary(vgg16, input_size=(32,3,224,224),col_names=['input_size','output_size','num_params','trainable'],col_width=25)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:06.223072Z","iopub.execute_input":"2023-09-22T04:34:06.225524Z","iopub.status.idle":"2023-09-22T04:34:16.809155Z","shell.execute_reply.started":"2023-09-22T04:34:06.22549Z","shell.execute_reply":"2023-09-22T04:34:16.808234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# tinyVGG Architecture\n#### Since the original VGG16 model is very expensive to train, both in terms of time and compute, we will experiment on a smaller model of the same architecture.\n> Architecture as per: https://poloclub.github.io/cnn-explainer/","metadata":{}},{"cell_type":"code","source":"class tinyVGG(nn.Module):\n    \"\"\"Implementation of tinyVGG model.\n        \n        Args:\n            input_shape - Input tensor shape.\n            hidden_units - Number of units for the intermediate convolution layers.\n            output_shape - Output tensor shape.\n    \"\"\"    \n    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n        super().__init__()\n        self.conv_block_1 = nn.Sequential(\n            nn.Conv2d(in_channels=input_shape,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=hidden_units,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1),\n            nn.BatchNorm2d(hidden_units),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.conv_block_2 = nn.Sequential(\n            nn.Conv2d(in_channels=hidden_units,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=hidden_units,\n                      out_channels=hidden_units,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1),\n            nn.BatchNorm2d(hidden_units),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(in_features=hidden_units*7*7,\n                      out_features=output_shape)\n        )\n\n    def forward(self, x):\n        x = self.conv_block_1(x)\n        x = self.conv_block_2(x)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:16.810699Z","iopub.execute_input":"2023-09-22T04:34:16.811284Z","iopub.status.idle":"2023-09-22T04:34:16.821648Z","shell.execute_reply.started":"2023-09-22T04:34:16.811252Z","shell.execute_reply":"2023-09-22T04:34:16.820693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tinyvgg = tinyVGG(input_shape=1,\n                 hidden_units=32,\n                 output_shape=len(class_names))\nsummary(tinyvgg, input_size=(32,1,28,28),col_names=['input_size','output_size','num_params','trainable'],col_width=25)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:16.824291Z","iopub.execute_input":"2023-09-22T04:34:16.824696Z","iopub.status.idle":"2023-09-22T04:34:16.856175Z","shell.execute_reply.started":"2023-09-22T04:34:16.824664Z","shell.execute_reply":"2023-09-22T04:34:16.855353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"markdown","source":"### Model Train Time Function","metadata":{}},{"cell_type":"code","source":"def print_train_time(start, end, device=None):\n    \"\"\"Prints difference between start and end time.\n\n    Args:\n        start (float): Start time of computation (preferred in timeit format).\n        end (float): End time of computation.\n        device ([type], optional): Device that compute is running on. Defaults to None.\n\n    Returns:\n        float: time between start and end in seconds (higher is longer).\n    \"\"\"\n    total_time = end - start\n    print(f\"\\nTrain time on {device}: {total_time:.3f} seconds\")\n    return total_time","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:16.857342Z","iopub.execute_input":"2023-09-22T04:34:16.857682Z","iopub.status.idle":"2023-09-22T04:34:16.862829Z","shell.execute_reply.started":"2023-09-22T04:34:16.857651Z","shell.execute_reply":"2023-09-22T04:34:16.862004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Accuracy Function","metadata":{}},{"cell_type":"code","source":"def accuracy_fn(y_true, y_pred):\n    \"\"\"Calculates accuracy between truth labels and predictions.\n\n    Args:\n        y_true (torch.Tensor): Truth labels for predictions.\n        y_pred (torch.Tensor): Predictions to be compared to predictions.\n\n    Returns:\n        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n    \"\"\"\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct / len(y_pred)) * 100\n    return acc","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:16.864081Z","iopub.execute_input":"2023-09-22T04:34:16.865048Z","iopub.status.idle":"2023-09-22T04:34:16.874492Z","shell.execute_reply.started":"2023-09-22T04:34:16.865017Z","shell.execute_reply":"2023-09-22T04:34:16.87361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train and Test Step Functions","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:16.875879Z","iopub.execute_input":"2023-09-22T04:34:16.87623Z","iopub.status.idle":"2023-09-22T04:34:16.884995Z","shell.execute_reply.started":"2023-09-22T04:34:16.876201Z","shell.execute_reply":"2023-09-22T04:34:16.883973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_step(\n    model: torch.nn.Module,\n    data_loader: torch.utils.data.DataLoader,\n    loss_fn: torch.nn.Module,\n    optimizer: torch.optim.Optimizer,\n    accuracy_fn,\n    device: torch.device = device):\n    \"\"\"Performs a single step of training.\n    \n        Args:\n            model: PyTorch model to train.\n            data_loader: DataLoader object to load train/ test image data.\n            loss_fn: Loss function to train model on.\n            optimizer: Optimizer to update model weights and biases.\n            accuracy_fn: Calculates model accuracy, either train/test.\n            device: Device (CPU/GPU/TPU)\n            \n        Returns:\n            Training loss, Training accuracy.\n    \"\"\"\n    # Initialize training loss and accuracy\n    train_loss, train_acc = 0, 0\n    \n    # Set model to 'train' mode.\n    model.train()\n    \n    # Iterate through DataLoader\n    for batch, (X, y) in enumerate(data_loader):\n        \n        # Send data to device\n        X, y = X.to(device), y.to(device)\n        \n        # Get predictions from model\n        y_pred = model(X)\n        \n        # Compute model loss and accuracy\n        loss = loss_fn(y_pred, y)\n        acc = accuracy_fn(y, y_pred.argmax(dim=1))\n        \n        # Accumulate training loss and accuracy\n        train_loss += loss\n        train_acc += acc\n        \n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    # Compute average training loss and accuracy\n    train_loss /= len(data_loader)\n    train_acc /= len(data_loader)\n    \n    print(f'Train loss: {train_loss:.4f} | Train accuracy: {train_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:16.88817Z","iopub.execute_input":"2023-09-22T04:34:16.888453Z","iopub.status.idle":"2023-09-22T04:34:16.899049Z","shell.execute_reply.started":"2023-09-22T04:34:16.888431Z","shell.execute_reply":"2023-09-22T04:34:16.898167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_step(\n    model: torch.nn.Module,\n    data_loader: torch.utils.data.DataLoader,\n    loss_fn: torch.nn.Module,\n    accuracy_fn,\n    device: torch.device = device):\n    \"\"\"Performs a single step of testing.\n    \n        Args:\n            model: PyTorch model to test.\n            data_loader: DataLoader object to load train/ test image data.\n            loss_fn: Loss function to test model on.\n            accuracy_fn: Calculates model accuracy, either train/test.\n            device: Device (CPU/GPU/TPU)\n            \n        Returns:\n            Testing loss, Testing accuracy.\n    \"\"\"\n    # Initialize testing loss and accuracy\n    test_loss, test_acc = 0, 0\n    \n    # Set model to 'evaluation' mode\n    model.eval()\n    \n    # Using torch.inference_mode() to ensure zero gradients, compute testing loss and accuracy\n    with torch.inference_mode():\n        # Iterate through DataLoader\n        for batch, (X, y) in enumerate(data_loader):\n            \n            # Send data to device\n            X, y = X.to(device), y.to(device)\n            \n            # Get predictions from model\n            y_pred = model(X)\n            \n            # Compute model loss and accuracy\n            loss = loss_fn(y_pred, y)\n            acc = accuracy_fn(y, y_pred.argmax(dim=1))\n            \n            # Accumulate testing loss and accuracy\n            test_loss += loss\n            test_acc += acc\n            \n        # Compute average testing loss and accuracy\n        test_loss /= len(data_loader)\n        test_acc /= len(data_loader)\n        \n    print(f'Test loss: {test_loss:.4f} | Test accuracy: {test_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:16.900464Z","iopub.execute_input":"2023-09-22T04:34:16.900788Z","iopub.status.idle":"2023-09-22T04:34:16.914152Z","shell.execute_reply.started":"2023-09-22T04:34:16.900758Z","shell.execute_reply":"2023-09-22T04:34:16.913208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Model Function","metadata":{}},{"cell_type":"code","source":"def train_model(\n    model: torch.nn.Module,\n    train_loader: torch.utils.data.DataLoader,\n    test_loader: torch.utils.data.DataLoader,\n    loss_fn: torch.nn.Module,\n    optimizer: torch.optim.Optimizer,\n    accuracy_fn,\n    epochs: int = 10,\n    device: torch.device = device):\n    \"\"\"Trains a model for specified number of epochs.\n        \n        Args:\n            model: PyTorch model to train.\n            train_loader: DataLoader object to load training image data.\n            test_loader: DataLoader object to load testing image data.\n            loss_fn: Loss function to train model on.\n            optimizer: Optimizer to update model weights and biases.\n            accuracy_fn: Calculates model accuracy, either train/test.\n            epochs: Number of epochs to train model for.\n            device: Device (CPU/GPU/TPU)\n            \n        Returns: \n            Training loss, Training accuracy, Testing loss, Testing accuracy, Total Training time.\n    \"\"\"\n    train_time_start = timer()\n    for epoch in trange(epochs):\n        print(f'Epoch: {epoch} \\n -----------------------')\n        \n        train_step(model, train_loader, loss_fn, optimizer, accuracy_fn, device)\n        test_step(model, test_loader, loss_fn, accuracy_fn, device)\n    \n    train_time_end = timer()\n    print_train_time(train_time_start, train_time_end, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:16.915652Z","iopub.execute_input":"2023-09-22T04:34:16.915989Z","iopub.status.idle":"2023-09-22T04:34:16.929722Z","shell.execute_reply.started":"2023-09-22T04:34:16.91596Z","shell.execute_reply":"2023-09-22T04:34:16.928857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training tinyVGG Model\n> Karpathy constant: https://twitter.com/karpathy/status/801621764144971776","metadata":{}},{"cell_type":"code","source":"epochs = 7\nlearning_rate = 3e-4  # Karpathy constant\nnum_classes = 100\n\nmodel = tinyVGG(input_shape=1,\n               hidden_units=32,\n               output_shape=len(class_names)).to(device)\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:16.931052Z","iopub.execute_input":"2023-09-22T04:34:16.931853Z","iopub.status.idle":"2023-09-22T04:34:16.946509Z","shell.execute_reply.started":"2023-09-22T04:34:16.931822Z","shell.execute_reply":"2023-09-22T04:34:16.945664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_model(model,\n           train_loader,\n           test_loader,\n           loss_fn,\n           optimizer,\n           accuracy_fn,\n           epochs,\n           device)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:34:16.950019Z","iopub.execute_input":"2023-09-22T04:34:16.950271Z","iopub.status.idle":"2023-09-22T04:35:47.9242Z","shell.execute_reply.started":"2023-09-22T04:34:16.95025Z","shell.execute_reply":"2023-09-22T04:35:47.92321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# tinyVGG Evaluation\n- Evaluating model\n- Making predictions\n- Plotting Confusion Matrix","metadata":{}},{"cell_type":"markdown","source":"### Model Evaluation Function","metadata":{}},{"cell_type":"code","source":"def eval_model(\n    model: torch.nn.Module,\n    data_loader: torch.utils.data.DataLoader,\n    loss_fn: torch.nn.Module,\n    accuracy_fn,\n    device: torch.device=device):\n    \"\"\"Returns a dictionary containing the results of model predictions on data_loader.\n       \n       Args:\n           model: PyTorch model to evaluate.\n           data_loader: DataLoader object to load testing images.\n           loss_fn: Loss function to test model on.\n           accuracy_fn: Calculates model accuracy, either train/test.\n           device: Device (CPU/GPU/TPU)\n    \"\"\"\n    # Initialize loss and accuracy \n    loss, acc = 0, 0\n    \n    # Set model to 'evaluate' mode\n    model.eval()\n    \n    # Compute loss and accuracy with torch.inference_mode() to ensure zero gradients\n    with torch.inference_mode():\n        # Iterate through data_loader\n        for X, y in tqdm(data_loader):\n            # Send data to device\n            X, y = X.to(device), y.to(device)\n            \n            # Computer model predictions\n            y_pred = model(X)\n            \n            # Compute and accumulate loss and accuracy\n            loss += loss_fn(y_pred, y)\n            acc += accuracy_fn(y, y_pred.argmax(dim=1))\n            \n        # Compute average loss and accuracy\n        loss /= len(data_loader)\n        acc /= len(data_loader)\n    \n    return {\n        'Model name' : model.__class__.__name__,\n        'Model loss' : loss.item(),\n        'Model accuracy' : acc\n    }","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:35:47.925527Z","iopub.execute_input":"2023-09-22T04:35:47.926728Z","iopub.status.idle":"2023-09-22T04:35:47.936519Z","shell.execute_reply.started":"2023-09-22T04:35:47.926691Z","shell.execute_reply":"2023-09-22T04:35:47.935438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tinyVGG_results = eval_model(model, test_loader, loss_fn, accuracy_fn)\ntinyVGG_results","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:35:47.937794Z","iopub.execute_input":"2023-09-22T04:35:47.938644Z","iopub.status.idle":"2023-09-22T04:35:49.257225Z","shell.execute_reply.started":"2023-09-22T04:35:47.938611Z","shell.execute_reply":"2023-09-22T04:35:49.255173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Predictions Function","metadata":{}},{"cell_type":"code","source":"def make_predictions(\n    model: torch.nn.Module,\n    data: list,\n    device: torch.device=device):\n    \n    \"\"\"Returns model's prediction probability tensor.\n        \n       Args:\n           model: PyTorch model to make predictions.\n           data: Data on which model will make predictions.\n           device: Device (CPU/GPU/TPU)\n    \"\"\"\n    # Initialize prediction probability list\n    pred_probs = []\n    \n    # Set model to 'evaluate' mode\n    model.eval()\n    \n    # Compute model prediction probabilities in torch.inference_mode() to ensure zero gradients\n    with torch.inference_mode():\n        # Iterate through data to generate predictions\n        for sample in data:\n            \n            # Reshaping data and sending it to device\n            sample = torch.unsqueeze(sample, dim=0).to(device)\n            \n            # Compute prediction logit from model\n            pred_logit = model(sample)\n            \n            # Compute prediction probability from prediction logit by apply softmax function\n            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n            \n            # Extending list of prediction probabilities\n            pred_probs.append(pred_prob.cpu())\n    return torch.stack(pred_probs)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:35:49.264265Z","iopub.execute_input":"2023-09-22T04:35:49.264673Z","iopub.status.idle":"2023-09-22T04:35:49.274879Z","shell.execute_reply.started":"2023-09-22T04:35:49.264638Z","shell.execute_reply":"2023-09-22T04:35:49.273986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compute Model Prediction Probabilities","metadata":{}},{"cell_type":"code","source":"test_samples = []\ntest_labels = []\n\nfor sample, label in random.sample(list(test_data),k=9):\n    test_samples.append(sample)\n    test_labels.append(label)\n    \npred_probs = make_predictions(model, test_samples)\npred_classes = pred_probs.argmax(dim=1)\npred_probs, pred_classes","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:35:49.276075Z","iopub.execute_input":"2023-09-22T04:35:49.276843Z","iopub.status.idle":"2023-09-22T04:35:50.357123Z","shell.execute_reply.started":"2023-09-22T04:35:49.27681Z","shell.execute_reply":"2023-09-22T04:35:50.356063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Results","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\nnrows = 3\nncols = 3\nfor i, sample in enumerate(test_samples):\n    plt.subplot(nrows, ncols, i+1)\n    plt.imshow(sample.squeeze())\n    title_txt = f\"True: {class_names[test_labels[i]]} | Pred: {class_names[pred_classes[i]]}\"\n    plt.axis(\"off\")\n    if class_names[pred_classes[i]] == class_names[test_labels[i]]:\n        plt.title(title_txt,c='g')\n    else:\n        plt.title(title_txt,c='r')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:35:50.358445Z","iopub.execute_input":"2023-09-22T04:35:50.358876Z","iopub.status.idle":"2023-09-22T04:35:51.221075Z","shell.execute_reply.started":"2023-09-22T04:35:50.358844Z","shell.execute_reply":"2023-09-22T04:35:51.219985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix","metadata":{}},{"cell_type":"code","source":"y_preds = []\nmodel.eval()\nwith torch.inference_mode():\n    for X, y in tqdm(test_loader, 'Making predictions...'):\n        X, y = X.to(device), y.to(device)\n        y_logit = model(X)\n        y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)\n        \n        y_preds.append(y_pred.cpu())\n        \ny_pred_tensor = torch.cat(y_preds)\ny_pred_tensor","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:35:51.222485Z","iopub.execute_input":"2023-09-22T04:35:51.222914Z","iopub.status.idle":"2023-09-22T04:35:52.521335Z","shell.execute_reply.started":"2023-09-22T04:35:51.222873Z","shell.execute_reply":"2023-09-22T04:35:52.520329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchmetrics import ConfusionMatrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nconfmat = ConfusionMatrix(task='multiclass',num_classes=len(class_names))\nconfmat_tensor = confmat(preds=y_pred_tensor, target=test_data.targets)\n\nfig, ax = plot_confusion_matrix(conf_mat=confmat_tensor.numpy(),\n                                class_names=class_names,\n                                figsize=(10,7))","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:35:52.522639Z","iopub.execute_input":"2023-09-22T04:35:52.523227Z","iopub.status.idle":"2023-09-22T04:35:53.389593Z","shell.execute_reply.started":"2023-09-22T04:35:52.523194Z","shell.execute_reply":"2023-09-22T04:35:53.388396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model","metadata":{}},{"cell_type":"code","source":"MODEL_PATH = Path('models')\nMODEL_PATH.mkdir(parents=True,exist_ok=True)\n\nMODEL_NAME = 'tinyVGG_fashionMNIST.pth'\nMODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n\nprint(f'Saving model to: {MODEL_SAVE_PATH}')\ntorch.save(model.state_dict(), MODEL_SAVE_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T04:35:53.390985Z","iopub.execute_input":"2023-09-22T04:35:53.391374Z","iopub.status.idle":"2023-09-22T04:35:53.405507Z","shell.execute_reply.started":"2023-09-22T04:35:53.391338Z","shell.execute_reply":"2023-09-22T04:35:53.404298Z"},"trusted":true},"execution_count":null,"outputs":[]}]}